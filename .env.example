# Ragussy Configuration
# Run the app and use the Setup Wizard at http://localhost:5173

# ===================
# Server Configuration
# ===================
PORT=3001
NODE_ENV=development

# ===================
# Project Identity
# ===================
# Name of your documentation project (used in prompts and responses)
PROJECT_NAME=My Documentation
# Base URL where your docs are hosted (for source links)
PUBLIC_DOCS_BASE_URL=https://docs.example.com

# ===================
# Document Source
# ===================
# Path to your documentation directory (relative or absolute)
DOCS_PATH=./docs
# File extensions to process (comma-separated)
DOCS_EXTENSIONS=.md,.mdx

# ===================
# Vector Database (Qdrant)
# ===================
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION=docs
# Vector dimension (3072 for text-embedding-3-large, 1536 for text-embedding-3-small)
VECTOR_DIM=1536

# ===================
# LLM Configuration
# ===================
# OpenAI-compatible API endpoint
# Options:
#   - https://api.openai.com/v1 (OpenAI)
#   - https://openrouter.ai/api/v1 (OpenRouter)
#   - https://rrq.ai/v1 (Rrequesty.ai)
#   - Any OpenAI-compatible endpoint
LLM_BASE_URL=https://api.openai.com/v1
LLM_API_KEY=your-api-key-here
LLM_MODEL=gpt-4o-mini
# Max tokens for LLM response
LLM_MAX_TOKENS=4096

# ===================
# Embeddings Configuration
# ===================
# Can use same or different provider than LLM
EMBED_BASE_URL=https://api.openai.com/v1
EMBED_API_KEY=your-api-key-here
EMBED_MODEL=text-embedding-3-small

# ===================
# RAG Configuration
# ===================
# Max context tokens to include in prompt
MAX_CONTEXT_TOKENS=4000
# Number of chunks to retrieve
RETRIEVAL_TOP_K=6
# Chunk size configuration
CHUNK_TARGET_TOKENS=500
CHUNK_MAX_TOKENS=700
CHUNK_OVERLAP_TOKENS=75
# Number of chunks to embed in a single batch (lower = fewer tokens per request, but slower)
# Reduce this if you hit token limit errors during embedding
EMBED_BATCH_SIZE=50

# ===================
# Security
# ===================
# API key for chat endpoint (min 16 chars)
API_KEY=generate-a-secure-api-key-here
# Admin token for reindex endpoints (min 16 chars)
ADMIN_TOKEN=generate-a-secure-token-here

# ===================
# Optional Features
# ===================
# Redis URL for caching (optional)
REDIS_URL=
# Logging level
LOG_LEVEL=info

# ===================
# Discord Bot (optional)
# ===================
# Enable Discord bot integration
DISCORD_BOT_ENABLED=false
# Discord bot token from Developer Portal
DISCORD_BOT_TOKEN=
# Discord application client ID
DISCORD_CLIENT_ID=
# Guild ID for faster command registration (optional)
DISCORD_GUILD_ID=
# Bot display name
DISCORD_BOT_NAME=Docs Bot
# Message command prefix
DISCORD_COMMAND_PREFIX=!docs
# Embed color (hex)
DISCORD_EMBED_COLOR=0x7c3aed
# Rate limit cooldown in seconds
DISCORD_COOLDOWN_SECONDS=5

# ===================
# Custom System Prompt (optional)
# ===================
# Override the default system prompt. Use {PROJECT_NAME} and {CONTEXT} placeholders.
# CUSTOM_SYSTEM_PROMPT=You are a helpful assistant for {PROJECT_NAME}. Answer based on: {CONTEXT}

# ===================
# Forum Ingestion Mode (optional)
# ===================
# Enable forum ingestion mode for threaded discussions
FORUM_MODE=false

# Ingestion Settings
FORUM_MAX_TOKENS=800
FORUM_OVERLAP_TOKENS=120
FORUM_ABSOLUTE_MAX_TOKENS=1024
FORUM_EMBEDDING_MODEL=baai/bge-m3
# Embed quoted content separately (default: false)
FORUM_EMBED_QUOTED_CONTENT=false
# Concurrent workers
FORUM_EMBEDDING_THREADS=6
FORUM_UPSERT_THREADS=4
# Skip unchanged posts via fingerprint comparison
FORUM_SKIP_UNCHANGED=true

# Retrieval Settings
# Group results by thread for context
FORUM_GROUP_BY_THREAD=true
# Apply time decay to favor recent posts
FORUM_TIME_DECAY=false
FORUM_TIME_DECAY_HALF_LIFE=365
# Max posts per thread in context
FORUM_MAX_POSTS_PER_THREAD=10
# Number of posts to retrieve
FORUM_RETRIEVAL_COUNT=30
